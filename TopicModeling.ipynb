{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1819bba",
   "metadata": {},
   "source": [
    "# Open the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fe9f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>country_name</th>\n",
       "      <th>speaker</th>\n",
       "      <th>position</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Mr. NAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33: May I first convey to our President the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Mr. DE PABLO PARDO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.\\t : It is a fortunate coincidence that pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Mr. McMAHON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.\\t  It is a pleasure for me to extend to y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Mr. KIRCHSCHLAEGER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.\\t  May I begin by expressing to Ambassado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>BEL</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Mr. HARMEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176. No doubt each of us, before coming up to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>BLR</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>Mr. GURINOVICH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n71.\\t. We are today mourning the untimely de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>BOL</td>\n",
       "      <td>Bolivia, Plurinational State of</td>\n",
       "      <td>Mr. CAMACHO OMISTE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.\\t  I wish to congratulate the President o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Mr. GIBSON BARBOZA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.\\tMr. President, I should like, first of all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Mr. SHARP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nThe General Assembly is fortunate indeed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>CMR</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>Mr. AHIDJO</td>\n",
       "      <td>President</td>\n",
       "      <td>: A year ago I came here as the Acting Preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>COG</td>\n",
       "      <td>Congo</td>\n",
       "      <td>Mr. ICKONGA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.\\t  I cannot begin my intervention without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>COL</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Mr. VASQUEZ CARRIZOSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr. President, this visit to the United Nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>CRI</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Mr. FACIO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.\\t  Mr. President, your election to the Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>CUB</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>Mr. ALARCON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.\\t  Mr. President, I should first like to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>DOM</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>Mr FERNANDEZ G.</td>\n",
       "      <td></td>\n",
       "      <td>\\n\\n\\n Mr. President, it was a source of great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Mr. YAZID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.  The delegation of Algeria is very pleased ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>ECU</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Mr. Benites</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.  It had been my hope that a loftier person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "      <td>Mr. SCHUMANN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.\\t  Within one month, when we celebrate the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>GBR</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sir Alec DOUGLASHOME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.\\t Mr. President, I should like first to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>GHA</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Mr. OWUSU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.\\t I should like to begin by congratulatin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session  year country                     country_name  \\\n",
       "0        25  1970     ALB                          Albania   \n",
       "1        25  1970     ARG                        Argentina   \n",
       "2        25  1970     AUS                        Australia   \n",
       "3        25  1970     AUT                          Austria   \n",
       "4        25  1970     BEL                          Belgium   \n",
       "5        25  1970     BLR                          Belarus   \n",
       "6        25  1970     BOL  Bolivia, Plurinational State of   \n",
       "7        25  1970     BRA                           Brazil   \n",
       "8        25  1970     CAN                           Canada   \n",
       "9        25  1970     CMR                         Cameroon   \n",
       "10       25  1970     COG                            Congo   \n",
       "11       25  1970     COL                         Colombia   \n",
       "12       25  1970     CRI                       Costa Rica   \n",
       "13       25  1970     CUB                             Cuba   \n",
       "14       25  1970     DOM               Dominican Republic   \n",
       "15       25  1970     DZA                          Algeria   \n",
       "16       25  1970     ECU                          Ecuador   \n",
       "17       25  1970     FRA                           France   \n",
       "18       25  1970     GBR                   United Kingdom   \n",
       "19       25  1970     GHA                            Ghana   \n",
       "\n",
       "                  speaker    position  \\\n",
       "0                 Mr. NAS         NaN   \n",
       "1      Mr. DE PABLO PARDO         NaN   \n",
       "2             Mr. McMAHON         NaN   \n",
       "3      Mr. KIRCHSCHLAEGER         NaN   \n",
       "4              Mr. HARMEL         NaN   \n",
       "5          Mr. GURINOVICH         NaN   \n",
       "6      Mr. CAMACHO OMISTE         NaN   \n",
       "7      Mr. GIBSON BARBOZA         NaN   \n",
       "8               Mr. SHARP         NaN   \n",
       "9              Mr. AHIDJO  President    \n",
       "10            Mr. ICKONGA         NaN   \n",
       "11  Mr. VASQUEZ CARRIZOSA         NaN   \n",
       "12              Mr. FACIO         NaN   \n",
       "13            Mr. ALARCON         NaN   \n",
       "14        Mr FERNANDEZ G.               \n",
       "15              Mr. YAZID         NaN   \n",
       "16            Mr. Benites         NaN   \n",
       "17           Mr. SCHUMANN         NaN   \n",
       "18   Sir Alec DOUGLASHOME         NaN   \n",
       "19              Mr. OWUSU         NaN   \n",
       "\n",
       "                                                 text  \n",
       "0   33: May I first convey to our President the co...  \n",
       "1   177.\\t : It is a fortunate coincidence that pr...  \n",
       "2   100.\\t  It is a pleasure for me to extend to y...  \n",
       "3   155.\\t  May I begin by expressing to Ambassado...  \n",
       "4   176. No doubt each of us, before coming up to ...  \n",
       "5   \\n71.\\t. We are today mourning the untimely de...  \n",
       "6   135.\\t  I wish to congratulate the President o...  \n",
       "7   1.\\tMr. President, I should like, first of all...  \n",
       "8   \\nThe General Assembly is fortunate indeed to ...  \n",
       "9   : A year ago I came here as the Acting Preside...  \n",
       "10  122.\\t  I cannot begin my intervention without...  \n",
       "11  Mr. President, this visit to the United Nation...  \n",
       "12  62.\\t  Mr. President, your election to the Pre...  \n",
       "13  1.\\t  Mr. President, I should first like to co...  \n",
       "14  \\n\\n\\n Mr. President, it was a source of great...  \n",
       "15  1.  The delegation of Algeria is very pleased ...  \n",
       "16  71.  It had been my hope that a loftier person...  \n",
       "17  84.\\t  Within one month, when we celebrate the...  \n",
       "18  110.\\t Mr. President, I should like first to s...  \n",
       "19  121.\\t I should like to begin by congratulatin...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = r\"C:\\Users\\Venkat Dyagala\\Desktop\\TBA_Class\\un-general-debates-blueprint (1).csv\"\n",
    "df = pd.read_csv(file)\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72235aac",
   "metadata": {},
   "source": [
    "# extracting text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c069db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\ufeffIt is indeed a pleasure for me and the members of my delegation to extend to Ambassador Garba our sincere congratulations on his election to the presidency of the forty-fourth session of the General Assembly. His election to this high office is a well-deserved tribute to his personal qualities and experience. I am fully confident that under his able and wise leadership the Assembly will further c'\n",
      "'\\ufeffI wish to join\\nother representatives in congratulating you, Sir, on\\nyour unanimous election as President of the fifty-sixth\\nsession of the General Assembly. We are confident that\\n27\\n\\nunder your able guidance the work of this General\\nAssembly session will be another milestone on the new\\ninternational scene, particularly in confronting the new\\nchallenges facing our world, especially after the\\nextre'\n"
     ]
    }
   ],
   "source": [
    "print(repr(df.iloc[2666][\"text\"][0:400]))\n",
    "print(repr(df.iloc[4726][\"text\"][0:400]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc4b0e66",
   "metadata": {},
   "source": [
    "# split speech into sentences  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a8f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df[\"paragraphs\"] = df[\"text\"].map(lambda text: re.split('\\.\\s*\\n', text))\n",
    "df[\"number_of_paragraphs\"] = df[\"paragraphs\"].map(len)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebf929c0",
   "metadata": {},
   "source": [
    "# getting TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9cd486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venkat Dyagala\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7507, 24611)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df['text'])\n",
    "tfidf_text_vectors.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec03c846",
   "metadata": {},
   "source": [
    "# Make a data frame of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99a2756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33: May I first convey to our President the co...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.\\tThe utilization of the United Nations to ...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.\\tThe whole of progressive mankind recalls ...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.\\tAll this has had well known consequences ...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.\\tOne of the undeniable proofs that the Uni...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.\\tUndoubtedly, such a state of affairs in t...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.\\tThe liberation movement at the world leve...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41.\\tPanic-stricken at the impetuous growth of...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42.\\tAlthough split by numerous contradictions...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43.\\tIn that connexion we can cite, simultaneo...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year\n",
       "0  33: May I first convey to our President the co...  1970\n",
       "1  35.\\tThe utilization of the United Nations to ...  1970\n",
       "2  36.\\tThe whole of progressive mankind recalls ...  1970\n",
       "3  37.\\tAll this has had well known consequences ...  1970\n",
       "4  38.\\tOne of the undeniable proofs that the Uni...  1970\n",
       "5  39.\\tUndoubtedly, such a state of affairs in t...  1970\n",
       "6  40.\\tThe liberation movement at the world leve...  1970\n",
       "7  41.\\tPanic-stricken at the impetuous growth of...  1970\n",
       "8  42.\\tAlthough split by numerous contradictions...  1970\n",
       "9  43.\\tIn that connexion we can cite, simultaneo...  1970"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten the paragraphs keeping the years\n",
    "paragraph_df = pd.DataFrame([{ \"text\": paragraph, \"year\": year } \n",
    "                               for paragraphs, year in zip(df[\"paragraphs\"], df[\"year\"]) \n",
    "                                    for paragraph in paragraphs if paragraph])\n",
    "paragraph_df.head(10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3431ce88",
   "metadata": {},
   "source": [
    "# Get the TFIDF of the sentences DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adfa0ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venkat Dyagala\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(279076, 25162)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_para_vectorizer = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "tfidf_para_vectors = tfidf_para_vectorizer.fit_transform(paragraph_df[\"text\"])\n",
    "tfidf_para_vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6e1ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venkat Dyagala\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Venkat Dyagala\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_text_model = NMF(n_components=10, random_state=42)\n",
    "W_text_matrix = nmf_text_model.fit_transform(tfidf_text_vectors)\n",
    "H_text_matrix = nmf_text_model.components_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71510b13",
   "metadata": {},
   "source": [
    "# getting 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4ac8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  co (0.79)\n",
      "  operation (0.65)\n",
      "  disarmament (0.36)\n",
      "  nuclear (0.34)\n",
      "  relations (0.25)\n",
      "\n",
      "Topic 01\n",
      "  terrorism (0.38)\n",
      "  challenges (0.32)\n",
      "  sustainable (0.30)\n",
      "  millennium (0.29)\n",
      "  reform (0.28)\n",
      "\n",
      "Topic 02\n",
      "  africa (1.15)\n",
      "  african (0.82)\n",
      "  south (0.63)\n",
      "  namibia (0.36)\n",
      "  delegation (0.30)\n",
      "\n",
      "Topic 03\n",
      "  arab (1.02)\n",
      "  israel (0.89)\n",
      "  palestinian (0.60)\n",
      "  lebanon (0.54)\n",
      "  israeli (0.54)\n",
      "\n",
      "Topic 04\n",
      "  american (0.33)\n",
      "  america (0.31)\n",
      "  latin (0.31)\n",
      "  panama (0.21)\n",
      "  bolivia (0.21)\n",
      "\n",
      "Topic 05\n",
      "  pacific (1.55)\n",
      "  islands (1.23)\n",
      "  solomon (0.86)\n",
      "  island (0.82)\n",
      "  fiji (0.71)\n",
      "\n",
      "Topic 06\n",
      "  soviet (0.81)\n",
      "  republic (0.78)\n",
      "  nuclear (0.68)\n",
      "  viet (0.64)\n",
      "  socialist (0.63)\n",
      "\n",
      "Topic 07\n",
      "  guinea (4.26)\n",
      "  equatorial (1.75)\n",
      "  bissau (1.53)\n",
      "  papua (1.47)\n",
      "  republic (0.57)\n",
      "\n",
      "Topic 08\n",
      "  european (0.61)\n",
      "  europe (0.44)\n",
      "  cooperation (0.39)\n",
      "  bosnia (0.34)\n",
      "  herzegovina (0.30)\n",
      "\n",
      "Topic 09\n",
      "  caribbean (0.98)\n",
      "  small (0.66)\n",
      "  bahamas (0.63)\n",
      "  saint (0.63)\n",
      "  barbados (0.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venkat Dyagala\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))\n",
    "display_topics(nmf_text_model, tfidf_text_vectorizer.get_feature_names()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a556720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, num_top_words=10):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04b685",
   "metadata": {},
   "source": [
    "# how big each topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66dd1423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.14353588, 17.10877242, 13.61965772, 10.16345439, 11.41042599,\n",
       "        5.93353622,  7.86636069,  4.13893748, 11.84152198,  6.77379723])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_text_matrix.sum(axis=0)/W_text_matrix.sum()*100.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e9733",
   "metadata": {},
   "source": [
    "# topic size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53881118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.61162166, 10.34430821, 10.16803041, 10.04420303,  6.63538336,\n",
       "        7.35268755,  8.9000421 ,  8.28986812, 16.7126125 , 10.94124304])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_para_matrix.sum(axis=0)/W_para_matrix.sum()*100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venkat Dyagala\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_para_vectorizer = CountVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "count_para_vectors = count_para_vectorizer.fit_transform(paragraph_df[\"text\"])\n",
    "count_para_vectors.shape\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_para_model = LatentDirichletAllocation(n_components = 10, random_state=42)\n",
    "W_lda_para_matrix = lda_para_model.fit_transform(count_para_vectors)\n",
    "H_lda_para_matrix = lda_para_model.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99453c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
